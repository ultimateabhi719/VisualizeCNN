{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b228dc3-86b8-4772-bd32-70c0ee363e44",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZmo6jbkzPbg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import  torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from transformers import ResNetForImageClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef10c910-7d88-4e51-943f-530cd3ce5ade",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-WsN9PsezS4t",
    "outputId": "763d8578-a4ee-4a9a-d756-dd9354f1e361",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load pretrained resnet model\n",
    "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "#define transforms to preprocess input image into format expected by model\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "#inverse transform to get normalize image back to original form for visualization\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "    std=[1/0.229, 1/0.224, 1/0.255]\n",
    ")\n",
    "\n",
    "#transforms to resize image to the size expected by pretrained model,\n",
    "#convert PIL image to tensor, and\n",
    "#normalize the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,          \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba3686e5-28ce-4bf8-aafe-03a15e80f527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "readImg = 'images/eagle.jpeg'\n",
    "# readImg = 'images/IndianElephant.jpg'\n",
    "# readImg = 'images/Elephas_maximus.jpg'\n",
    "img0 = Image.open(readImg).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f1cfe-00e9-488e-84e8-fab965b27c16",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981a2f9-8067-4b1e-b218-354491baf2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def getActivation(name):\n",
    "    # the hook signature\n",
    "    def hook(module, input, output):\n",
    "        activation[name] = output.detach().cpu().numpy()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87478420-efc9-4f6a-8efa-68746bc132d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.resnet.encoder.stages[-1].register_forward_hook(getActivation('last_stage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b783e2-b7e4-4f8b-8cbb-2fb4651b0a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = list(model.classifier[1].parameters())\n",
    "\n",
    "weight = np.squeeze(params[0].data.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe438b6-b97a-4124-b44a-b1cda3f512dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_CAM(feature_conv, weight, class_idx):\n",
    "    # generate the class -activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        beforeDot =  feature_conv.reshape((nc, h*w))\n",
    "        cam = np.matmul(weight[idx], beforeDot)\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8809c8-9a8e-4f9b-a1fa-d794f132c361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "logit = model(transform(img0).unsqueeze(0)).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f71b1-12c1-4c8a-b963-4a8284872563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "\n",
    "probs, idx = h_x.sort(0, True)\n",
    "probs = probs.detach().numpy()\n",
    "idx = idx.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701902cd-dd5d-43db-bad5-7d8e0e4946e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CAMs = return_CAM(activation['last_stage'], weight, [idx[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3bbc6-42fc-42ad-915b-8f0d04aff078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(readImg)\n",
    "height, width, _ = img.shape\n",
    "heatmap = cv2.applyColorMap(cv2.resize(CAMs[0],(width, height)), cv2.COLORMAP_JET)\n",
    "result = heatmap * 0.5 + img * 0.5\n",
    "\n",
    "cv2.imwrite(\"image_1.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad25b8-aa8d-4792-9ad2-3abb2416d683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.config.id2label[idx[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d4f69e-561b-420a-ac3c-eb81f522349c",
   "metadata": {},
   "source": [
    "# Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b272125-a29a-475d-be6a-0af3c5d0f99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defines two global scope variables to store our gradients and activations\n",
    "gradients = {}\n",
    "activations = {}\n",
    "\n",
    "def getGradients(name):\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients[name] = grad_output\n",
    "    return backward_hook\n",
    "\n",
    "def getActivations(name):\n",
    "    def forward_hook(module, args, output):\n",
    "        activations[name] = output\n",
    "    return forward_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19371e58-c291-4339-bbb0-5c1819124254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backward_hook = model.resnet.encoder.stages[-1].layers[-1].register_backward_hook(getGradients('lastLayer'))\n",
    "forward_hook = model.resnet.encoder.stages[-1].layers[-1].register_forward_hook(getActivations('lastLayer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea6f78a-b431-42a2-9aa4-07fe8338ec78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python3.7/site-packages/torch/nn/modules/module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "logit = model(transform(img0).unsqueeze(0)).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b2c6e7-b27d-4b52-9f4d-45af1ecc1f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kite'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "\n",
    "probs, idx = h_x.sort(0, True)\n",
    "probs = probs.detach().numpy()\n",
    "idx = idx.numpy()\n",
    "model.config.id2label[idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78682268-6b71-473b-9b67-742231905288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logit[0,idx[0]].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5024f091-8b73-45ac-b70f-af3de5daae4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients['lastLayer'][0], dim=[0, 2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df277a7f-d5b3-4712-b8d6-f4b2daf3c001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f20a7bfab50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(activations['lastLayer'].size()[1]):\n",
    "    activations['lastLayer'][:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations['lastLayer'], dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "heatmap = F.relu(heatmap).detach().cpu().numpy()\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap = heatmap - np.min(heatmap)\n",
    "heatmap_img = heatmap / np.max(heatmap)\n",
    "heatmap_img = np.uint8(255 * heatmap_img)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3db02f4-fc29-4602-bfc0-c635625b77e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(readImg)\n",
    "height, width, _ = img.shape\n",
    "_heatmap = cv2.applyColorMap(cv2.resize(heatmap_img,(width, height)), cv2.COLORMAP_JET)\n",
    "result = _heatmap * 0.5 + img * 0.5\n",
    "\n",
    "cv2.imwrite(\"image_1.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66624f5e-40f0-4fde-92da-3152efb17e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
